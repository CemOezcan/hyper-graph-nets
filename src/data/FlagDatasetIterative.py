
import torch
import os

from torch.utils.data import IterableDataset
from tfrecord.torch.dataset import TFRecordDataset


class FlagDatasetIterative(IterableDataset):
    def __init__(self, path, split, add_targets=False, split_and_preprocess=False):
        self.path = path
        self.split = split
        self._add_targets = add_targets
        self._split_and_preprocess = split_and_preprocess
        tfrecord_path = os.path.join(path, split + ".tfrecord")
        # index is generated by tfrecord2idx
        index_path = os.path.join(path, split + ".idx")
        tf_dataset = TFRecordDataset(tfrecord_path, index_path, None)
        # loader and iter(loader) have size 1000, which is the number of all training trajectories
        # TODO Batch Size is set to 1 here, maybe this is what causes the error
        loader = torch.utils.data.DataLoader(tf_dataset, batch_size=1)
        # use list to make list from iterable so that the order of elements is ensured
        self.dataset = iter(loader)

    def __iter__(self):
        return self.dataset
